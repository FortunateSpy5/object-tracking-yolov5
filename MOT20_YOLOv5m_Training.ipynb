{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrsaDfdVHzxt"
      },
      "source": [
        "# Custom Training with YOLOv5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfWJk6SZA0_D"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNSkPeUtBDHj",
        "outputId": "87900fc8-77bc-444c-a68f-a264ec3c6d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Project/Tracking\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/Project/Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNveqeA1KXGy"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvDNSILZoN9",
        "outputId": "9aa8bd21-1733-48a7-c596-306b65431744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 13180, done.\u001b[K\n",
            "remote: Total 13180 (delta 0), reused 0 (delta 0), pack-reused 13180\u001b[K\n",
            "Receiving objects: 100% (13180/13180), 11.96 MiB | 7.84 MiB/s, done.\n",
            "Resolving deltas: 100% (9168/9168), done.\n",
            "/content/yolov5/yolov5\n",
            "Setup complete. Using torch 1.11.0+cu113 (Tesla K80)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "%pip install -q wandb\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP6USLgz2f0r"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wGvjd4Z_92",
        "outputId": "2d3c8d7a-b471-4ad6-a2eb-a8e352ae0900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjT5uIHo6l5"
      },
      "outputs": [],
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwJcaoPGF4VI",
        "outputId": "86e978fe-302c-4508-d17e-0c14f58c6930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in /content/datasets/YOLOv5-4 to yolov5pytorch: 100% [464081748 / 464081748] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to /content/datasets/YOLOv5-4 in yolov5pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17871/17871 [00:23<00:00, 767.07it/s] \n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Jk9USaGb7T5W0R8f0VUy\")\n",
        "project = rf.workspace(\"yolov5-deepsort-2kymo\").project(\"yolov5-oxvbs\")\n",
        "dataset = project.version(4).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1uVvc6Bt8Qt",
        "outputId": "598d0499-9929-4998-c26f-51a885369672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-05 14:50:07--  https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/77bb6f54-77c5-4161-b921-b225b7bb730e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220505T145007Z&X-Amz-Expires=300&X-Amz-Signature=9c0706d6f44dc4e17aea2ad2c56469d46141cf6830c634a13f15e01dfa4055c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-05-05 14:50:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/77bb6f54-77c5-4161-b921-b225b7bb730e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220505T145007Z&X-Amz-Expires=300&X-Amz-Signature=9c0706d6f44dc4e17aea2ad2c56469d46141cf6830c634a13f15e01dfa4055c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42806829 (41M) [application/octet-stream]\n",
            "Saving to: ‚Äòyolov5m.pt‚Äô\n",
            "\n",
            "yolov5m.pt          100%[===================>]  40.82M  18.7MB/s    in 2.2s    \n",
            "\n",
            "2022-05-05 14:50:10 (18.7 MB/s) - ‚Äòyolov5m.pt‚Äô saved [42806829/42806829]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yAi9hd-T4B"
      },
      "source": [
        "# Train Our Custom YOLOv5 model\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiEZsjCOtdyc",
        "outputId": "1fcadf00-c263-464a-a2f1-17615b9a12a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFNnxLJbq4J",
        "outputId": "42bbfcb2-0415-4953-d344-4ccdcad099c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfortunatespy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=datasets/YOLOv5-4/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[10], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v6.1-174-gc4cb7c6 torch 1.11.0+cu113 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220505_145456-ao486o8d\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrogue-podracer-22\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/fortunatespy/train\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/fortunatespy/train/runs/ao486o8d\u001b[0m\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 5.26MB/s]\n",
            "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "Model summary: 369 layers, 20871318 parameters, 20871318 gradients, 48.0 GFLOPs\n",
            "\n",
            "Transferred 475/481 items from yolov5m.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.cv1.conv.weight\n",
            "freezing model.2.cv1.bn.weight\n",
            "freezing model.2.cv1.bn.bias\n",
            "freezing model.2.cv2.conv.weight\n",
            "freezing model.2.cv2.bn.weight\n",
            "freezing model.2.cv2.bn.bias\n",
            "freezing model.2.cv3.conv.weight\n",
            "freezing model.2.cv3.bn.weight\n",
            "freezing model.2.cv3.bn.bias\n",
            "freezing model.2.m.0.cv1.conv.weight\n",
            "freezing model.2.m.0.cv1.bn.weight\n",
            "freezing model.2.m.0.cv1.bn.bias\n",
            "freezing model.2.m.0.cv2.conv.weight\n",
            "freezing model.2.m.0.cv2.bn.weight\n",
            "freezing model.2.m.0.cv2.bn.bias\n",
            "freezing model.2.m.1.cv1.conv.weight\n",
            "freezing model.2.m.1.cv1.bn.weight\n",
            "freezing model.2.m.1.cv1.bn.bias\n",
            "freezing model.2.m.1.cv2.conv.weight\n",
            "freezing model.2.m.1.cv2.bn.weight\n",
            "freezing model.2.m.1.cv2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.cv1.conv.weight\n",
            "freezing model.4.cv1.bn.weight\n",
            "freezing model.4.cv1.bn.bias\n",
            "freezing model.4.cv2.conv.weight\n",
            "freezing model.4.cv2.bn.weight\n",
            "freezing model.4.cv2.bn.bias\n",
            "freezing model.4.cv3.conv.weight\n",
            "freezing model.4.cv3.bn.weight\n",
            "freezing model.4.cv3.bn.bias\n",
            "freezing model.4.m.0.cv1.conv.weight\n",
            "freezing model.4.m.0.cv1.bn.weight\n",
            "freezing model.4.m.0.cv1.bn.bias\n",
            "freezing model.4.m.0.cv2.conv.weight\n",
            "freezing model.4.m.0.cv2.bn.weight\n",
            "freezing model.4.m.0.cv2.bn.bias\n",
            "freezing model.4.m.1.cv1.conv.weight\n",
            "freezing model.4.m.1.cv1.bn.weight\n",
            "freezing model.4.m.1.cv1.bn.bias\n",
            "freezing model.4.m.1.cv2.conv.weight\n",
            "freezing model.4.m.1.cv2.bn.weight\n",
            "freezing model.4.m.1.cv2.bn.bias\n",
            "freezing model.4.m.2.cv1.conv.weight\n",
            "freezing model.4.m.2.cv1.bn.weight\n",
            "freezing model.4.m.2.cv1.bn.bias\n",
            "freezing model.4.m.2.cv2.conv.weight\n",
            "freezing model.4.m.2.cv2.bn.weight\n",
            "freezing model.4.m.2.cv2.bn.bias\n",
            "freezing model.4.m.3.cv1.conv.weight\n",
            "freezing model.4.m.3.cv1.bn.weight\n",
            "freezing model.4.m.3.cv1.bn.bias\n",
            "freezing model.4.m.3.cv2.conv.weight\n",
            "freezing model.4.m.3.cv2.bn.weight\n",
            "freezing model.4.m.3.cv2.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.cv1.conv.weight\n",
            "freezing model.6.cv1.bn.weight\n",
            "freezing model.6.cv1.bn.bias\n",
            "freezing model.6.cv2.conv.weight\n",
            "freezing model.6.cv2.bn.weight\n",
            "freezing model.6.cv2.bn.bias\n",
            "freezing model.6.cv3.conv.weight\n",
            "freezing model.6.cv3.bn.weight\n",
            "freezing model.6.cv3.bn.bias\n",
            "freezing model.6.m.0.cv1.conv.weight\n",
            "freezing model.6.m.0.cv1.bn.weight\n",
            "freezing model.6.m.0.cv1.bn.bias\n",
            "freezing model.6.m.0.cv2.conv.weight\n",
            "freezing model.6.m.0.cv2.bn.weight\n",
            "freezing model.6.m.0.cv2.bn.bias\n",
            "freezing model.6.m.1.cv1.conv.weight\n",
            "freezing model.6.m.1.cv1.bn.weight\n",
            "freezing model.6.m.1.cv1.bn.bias\n",
            "freezing model.6.m.1.cv2.conv.weight\n",
            "freezing model.6.m.1.cv2.bn.weight\n",
            "freezing model.6.m.1.cv2.bn.bias\n",
            "freezing model.6.m.2.cv1.conv.weight\n",
            "freezing model.6.m.2.cv1.bn.weight\n",
            "freezing model.6.m.2.cv1.bn.bias\n",
            "freezing model.6.m.2.cv2.conv.weight\n",
            "freezing model.6.m.2.cv2.bn.weight\n",
            "freezing model.6.m.2.cv2.bn.bias\n",
            "freezing model.6.m.3.cv1.conv.weight\n",
            "freezing model.6.m.3.cv1.bn.weight\n",
            "freezing model.6.m.3.cv1.bn.bias\n",
            "freezing model.6.m.3.cv2.conv.weight\n",
            "freezing model.6.m.3.cv2.bn.weight\n",
            "freezing model.6.m.3.cv2.bn.bias\n",
            "freezing model.6.m.4.cv1.conv.weight\n",
            "freezing model.6.m.4.cv1.bn.weight\n",
            "freezing model.6.m.4.cv1.bn.bias\n",
            "freezing model.6.m.4.cv2.conv.weight\n",
            "freezing model.6.m.4.cv2.bn.weight\n",
            "freezing model.6.m.4.cv2.bn.bias\n",
            "freezing model.6.m.5.cv1.conv.weight\n",
            "freezing model.6.m.5.cv1.bn.weight\n",
            "freezing model.6.m.5.cv1.bn.bias\n",
            "freezing model.6.m.5.cv2.conv.weight\n",
            "freezing model.6.m.5.cv2.bn.weight\n",
            "freezing model.6.m.5.cv2.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.cv1.conv.weight\n",
            "freezing model.8.cv1.bn.weight\n",
            "freezing model.8.cv1.bn.bias\n",
            "freezing model.8.cv2.conv.weight\n",
            "freezing model.8.cv2.bn.weight\n",
            "freezing model.8.cv2.bn.bias\n",
            "freezing model.8.cv3.conv.weight\n",
            "freezing model.8.cv3.bn.weight\n",
            "freezing model.8.cv3.bn.bias\n",
            "freezing model.8.m.0.cv1.conv.weight\n",
            "freezing model.8.m.0.cv1.bn.weight\n",
            "freezing model.8.m.0.cv1.bn.bias\n",
            "freezing model.8.m.0.cv2.conv.weight\n",
            "freezing model.8.m.0.cv2.bn.weight\n",
            "freezing model.8.m.0.cv2.bn.bias\n",
            "freezing model.8.m.1.cv1.conv.weight\n",
            "freezing model.8.m.1.cv1.bn.weight\n",
            "freezing model.8.m.1.cv1.bn.bias\n",
            "freezing model.8.m.1.cv2.conv.weight\n",
            "freezing model.8.m.1.cv2.bn.weight\n",
            "freezing model.8.m.1.cv2.bn.bias\n",
            "freezing model.9.cv1.conv.weight\n",
            "freezing model.9.cv1.bn.weight\n",
            "freezing model.9.cv1.bn.bias\n",
            "freezing model.9.cv2.conv.weight\n",
            "freezing model.9.cv2.bn.weight\n",
            "freezing model.9.cv2.bn.bias\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla K80) 11.17G total, 0.17G reserved, 0.16G allocated, 10.84G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "    20871318       48.03         0.296         86.01         50.11        (1, 3, 640, 640)                    list\n",
            "    20871318       96.07         0.401         110.2         51.91        (2, 3, 640, 640)                    list\n",
            "    20871318       192.1         0.573         192.1         81.36        (4, 3, 640, 640)                    list\n",
            "    20871318       384.3         1.164         360.4         162.4        (8, 3, 640, 640)                    list\n",
            "    20871318       768.6         2.129         683.8         353.9       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 77 for CUDA:0 10.06G/11.17G (90%)\n",
            "Scaled weight_decay = 0.0006015625\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/YOLOv5-4/train/labels' images and labels...7138 found, 0 missing, 0 empty, 0 corrupt: 100% 7138/7138 [00:07<00:00, 902.13it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/datasets/YOLOv5-4/train/images/000919_jpg.rf.7041aea0127b820c612b6a4d6c95958f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/datasets/YOLOv5-4/train/images/004451_jpg.rf.ea8d2844a22d916f3cafe2307d0b08c3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/datasets/YOLOv5-4/train/images/006579_jpg.rf.03f8fdcdd4dd48ec16177fef1e76b420.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/datasets/YOLOv5-4/train/images/007814_jpg.rf.a2bdd78ecc1d603fbec6eebce1fdd2e9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/datasets/YOLOv5-4/train/images/008631_jpg.rf.feaf92a180d6d96f5db782dd845065b1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/YOLOv5-4/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/YOLOv5-4/valid/labels' images and labels...1793 found, 0 missing, 0 empty, 0 corrupt: 100% 1793/1793 [00:04<00:00, 431.10it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: /content/datasets/YOLOv5-4/valid/images/000926_jpg.rf.74990311614cb1fe92adc2284b33fab5.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: /content/datasets/YOLOv5-4/valid/images/002628_jpg.rf.f2187c5729c60a527a56eabc107eabfc.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/YOLOv5-4/valid/labels.cache\n",
            "Plotting labels to yolov5/runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.39 anchors/target, 0.998 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/49     9.18G   0.08529     0.668         0 1.306e+04       640: 100% 93/93 [09:57<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:17<00:00,  6.43s/it]\n",
            "                 all       1793     249025      0.538      0.693      0.635      0.289\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/49     7.48G   0.06652    0.6185         0 1.383e+04       640: 100% 93/93 [09:55<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:12<00:00,  6.01s/it]\n",
            "                 all       1793     249025      0.884      0.806      0.875      0.424\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/49     7.48G   0.06181    0.6004         0 1.234e+04       640: 100% 93/93 [09:55<00:00,  6.40s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:11<00:00,  5.92s/it]\n",
            "                 all       1793     249025      0.935      0.838      0.921       0.51\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/49     7.48G   0.05822    0.5751         0 1.416e+04       640: 100% 93/93 [09:55<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:11<00:00,  5.92s/it]\n",
            "                 all       1793     249025      0.934      0.858      0.931      0.492\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/49     7.48G   0.05624    0.5624         0 1.218e+04       640: 100% 93/93 [09:54<00:00,  6.39s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:12<00:00,  6.05s/it]\n",
            "                 all       1793     249025       0.95      0.866       0.94      0.562\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/49     7.48G   0.05471    0.5517         0 1.109e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.88s/it]\n",
            "                 all       1793     249025      0.964      0.851      0.937       0.55\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/49     8.75G   0.05433    0.5467         0 1.307e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.89s/it]\n",
            "                 all       1793     249025       0.96      0.879      0.949      0.586\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/49     8.75G   0.05395    0.5371         0 1.305e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.89s/it]\n",
            "                 all       1793     249025      0.954      0.881      0.949      0.563\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/49     8.75G   0.05307    0.5315         0 1.252e+04       640: 100% 93/93 [09:55<00:00,  6.40s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.89s/it]\n",
            "                 all       1793     249025      0.961      0.885      0.952      0.608\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/49     8.75G   0.05288    0.5338         0 1.396e+04       640: 100% 93/93 [09:54<00:00,  6.39s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:12<00:00,  6.05s/it]\n",
            "                 all       1793     249025      0.961      0.884      0.952      0.569\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/49     8.75G   0.05243    0.5256         0 1.244e+04       640: 100% 93/93 [09:54<00:00,  6.40s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.88s/it]\n",
            "                 all       1793     249025      0.966      0.888      0.955      0.604\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/49     8.75G   0.05247    0.5216         0 1.222e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.88s/it]\n",
            "                 all       1793     249025      0.969      0.881      0.954       0.62\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/49     8.75G    0.0518    0.5205         0 1.313e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.87s/it]\n",
            "                 all       1793     249025      0.963      0.895      0.958      0.616\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/49     8.75G   0.05164    0.5187         0 1.399e+04       640: 100% 93/93 [09:55<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.87s/it]\n",
            "                 all       1793     249025      0.964      0.896      0.959      0.618\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/49     8.75G    0.0514    0.5164         0 1.074e+04       640: 100% 93/93 [09:54<00:00,  6.39s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:11<00:00,  5.99s/it]\n",
            "                 all       1793     249025       0.97      0.891      0.959      0.638\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/49     8.75G    0.0514    0.5125         0 1.161e+04       640: 100% 93/93 [09:54<00:00,  6.40s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.86s/it]\n",
            "                 all       1793     249025      0.971       0.89      0.958      0.641\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/49     8.75G   0.05128     0.513         0 1.259e+04       640: 100% 93/93 [09:54<00:00,  6.39s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.85s/it]\n",
            "                 all       1793     249025      0.969      0.896       0.96      0.638\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/49     8.75G   0.05089    0.5088         0 1.312e+04       640: 100% 93/93 [09:54<00:00,  6.39s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.86s/it]\n",
            "                 all       1793     249025      0.967      0.897      0.961      0.637\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/49     8.75G    0.0508    0.5065         0 1.103e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.87s/it]\n",
            "                 all       1793     249025      0.969      0.899      0.961      0.646\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/49     8.75G   0.05087    0.5133         0 1.099e+04       640: 100% 93/93 [09:56<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:11<00:00,  5.98s/it]\n",
            "                 all       1793     249025      0.967      0.901      0.962      0.639\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/49     8.75G    0.0505    0.5082         0 1.319e+04       640: 100% 93/93 [09:57<00:00,  6.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.86s/it]\n",
            "                 all       1793     249025      0.966      0.904      0.962      0.629\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/49     8.75G   0.05043    0.5017         0 1.226e+04       640: 100% 93/93 [09:57<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.85s/it]\n",
            "                 all       1793     249025      0.973      0.898      0.962      0.647\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/49     8.75G   0.05039    0.5049         0 1.484e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.971      0.902      0.963      0.651\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/49     8.75G   0.05021    0.5038         0 1.267e+04       640: 100% 93/93 [09:57<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.973        0.9      0.963      0.648\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/49     8.75G   0.04975    0.4987         0 1.224e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:11<00:00,  5.97s/it]\n",
            "                 all       1793     249025      0.973      0.901      0.963      0.655\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/49     8.75G    0.0499    0.4985         0 1.198e+04       640: 100% 93/93 [09:56<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.971      0.905      0.964      0.647\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/49     8.75G   0.04978    0.4953         0 1.492e+04       640: 100% 93/93 [09:56<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.84s/it]\n",
            "                 all       1793     249025       0.97      0.906      0.964      0.648\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/49     8.75G   0.04969    0.4947         0 1.232e+04       640: 100% 93/93 [09:56<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:09<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.972      0.903      0.964      0.651\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/49     8.75G   0.04944    0.4953         0 1.385e+04       640: 100% 93/93 [09:57<00:00,  6.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:09<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.976      0.901      0.964      0.663\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/49     8.75G   0.04949    0.4935         0 1.168e+04       640: 100% 93/93 [09:57<00:00,  6.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:11<00:00,  5.95s/it]\n",
            "                 all       1793     249025      0.975      0.902      0.965      0.657\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/49     8.75G    0.0495    0.4951         0 1.257e+04       640: 100% 93/93 [09:57<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:09<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.976      0.903      0.965       0.66\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     31/49     8.75G   0.04927    0.4911         0 1.127e+04       640: 100% 93/93 [09:56<00:00,  6.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:09<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.974      0.906      0.965      0.665\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     32/49     8.75G   0.04904    0.4871         0 1.312e+04       640: 100% 93/93 [09:56<00:00,  6.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:10<00:00,  5.85s/it]\n",
            "                 all       1793     249025      0.977      0.904      0.966      0.665\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     33/49     8.75G   0.04939    0.4945         0  1.33e+04       640: 100% 93/93 [09:57<00:00,  6.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [01:09<00:00,  5.83s/it]\n",
            "                 all       1793     249025      0.975      0.906      0.965      0.662\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     34/49     8.75G   0.04893    0.4876         0 1.887e+04       640:  84% 78/93 [08:23<01:36,  6.45s/it]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "!python yolov5/train.py --img 640 --batch -1 --epochs 50 --data datasets/YOLOv5-4/data.yaml --weights yolov5m.pt --freeze 10"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "YOLOv5-Custom-Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('object-detection')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f05fa5f3d147c45ff393dc58dfdd6ed249791f1cb50020ac01b74bfaf02c64ad"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
